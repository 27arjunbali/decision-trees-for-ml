{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM Hello World Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to mention Microsoft LightGBM framework on a simple data set. This includes both preprocessing steps and modelling parts. You may change the source data set and run this notebook again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "You need to install these packages by running the following command\n",
    "\n",
    "pip install pandas numpy lightgbm graphviz matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot built decision tree you need to download graphviz from the following link\n",
    "\n",
    "https://graphviz.gitlab.io/_pages/Download/Download_windows.html\n",
    "\n",
    "You will specify the installed path in the following block. If you haven't installed graphviz, please set plotTree variable to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin' #be sure where graphviz installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_regression = False #set this True to run classification\n",
    "plotTree = False #if you haven't installed graphviz set this to False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to work on playing golf decision data set.\n",
    "\n",
    "You can find the raw data set here: https://github.com/serengil/decision-trees-for-ml/tree/master/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('C:/Users/IS96273/Desktop/decision tree/dataset/golf2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen loaded data set includes both continuous and string features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding\n",
    "\n",
    "LightGBM framework expects to convert categorical features to integer before constructing the dataset. That's why, we are going to apply label encoding to categorical features\n",
    "\n",
    "Ref: https://lightgbm.readthedocs.io/en/latest/Python-Intro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "features = []; categorical_features = []\n",
    "\n",
    "num_of_rows = dataset.shape[0]\n",
    "num_of_columns = dataset.shape[1]\n",
    "num_of_classes = 1 #default value is 1 for regression. we will update this for classification.\n",
    "\n",
    "for i in range(0, num_of_columns):\n",
    "    column_name = dataset.columns[i]\n",
    "    column_type = dataset[column_name].dtypes\n",
    "    \n",
    "    if i != num_of_columns - 1: #skip target\n",
    "        features.append(column_name)\n",
    "    \n",
    "    if column_type == 'object':\n",
    "        #encode with sklearn\n",
    "        le.fit(dataset[column_name])\n",
    "        feature_classes = list(le.classes_)\n",
    "        #print(feature_classes)\n",
    "        \n",
    "        encoded_feature = le.transform(dataset[column_name])\n",
    "        dataset[column_name] = pd.DataFrame(encoded_feature)\n",
    "        \n",
    "        #encode with manually\n",
    "        \"\"\"feature_classes = dataset[column_name].unique()\n",
    "        \n",
    "        for j in range(len(feature_classes)):\n",
    "            feature_class = feature_classes[j]\n",
    "            print(feature_class,\" -> \",j,\", \",end='')\n",
    "                        \n",
    "            dataset[column_name] = dataset[column_name].replace(feature_class, str(j))\"\"\"\n",
    "        \n",
    "        if i != num_of_columns - 1: #skip target\n",
    "            categorical_features.append(column_name)\n",
    "        \n",
    "        if is_regression == False and i == num_of_columns - 1:\n",
    "            num_of_classes = len(feature_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"num_of_classes: \",num_of_classes)\n",
    "print(\"features: \",features)\n",
    "print(\"categorical features: \",categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = dataset.columns[num_of_columns - 1] #target is the final column at the right on data set\n",
    "\n",
    "y_train = dataset[target_name].values\n",
    "x_train = dataset.drop(columns=[target_name]).values\n",
    "\n",
    "print(\"input features:\\n\",x_train)\n",
    "print(\"--------------------\")\n",
    "print(\"output:\\n\",y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to create data set for LightGBM. We have already transformed categorical features to integer in previous steps. Here, we have to define categorical features. Otherwise, decision node will check instance's that feature greater than some threshold or less than the threshold. Suppose that feature is related to gender information and values are -1 for unknown, 0 for man and 1 for woman. In this case, decision node might check that gender information is greater than -1. This might cause a trouble. That's why, specifying categorical features is very important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(x_train, y_train\n",
    "    ,feature_name = features\n",
    "    , categorical_feature = categorical_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train'\n",
    "    , 'boosting_type': 'gbdt'\n",
    "    , 'objective': 'regression' if is_regression == True else 'multiclass'\n",
    "    , 'num_class': num_of_classes\n",
    "    , 'metric': 'rmsle' if is_regression == True else 'multi_logloss'\n",
    "    , 'min_data': 1\n",
    "    #, 'learning_rate':0.1\n",
    "    , 'verbose': -1\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params, lgb_train, num_boost_round=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gbm.predict(x_train)\n",
    "\n",
    "print(predictions)\n",
    "\"\"\"for i in predictions:\n",
    "    print(np.argmax(i))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, instance in dataset.iterrows():\n",
    "    actual = instance[target_name]\n",
    "    \n",
    "    if is_regression == True:\n",
    "        prediction = round(predictions[index])\n",
    "    else: #classification\n",
    "        prediction = np.argmax(predictions[index])\n",
    "    \n",
    "    print((index+1),\". actual= \",actual,\", prediction= \",prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if plotTree == True:\n",
    "    \n",
    "    fig_size = [30, 20]\n",
    "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "    ax = lgb.plot_tree(gbm)\n",
    "    plt.show()\n",
    "    \n",
    "    #ax = lgb.plot_importance(gbm, max_num_features=10)\n",
    "    #plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
